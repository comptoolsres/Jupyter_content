{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch 12 Networked Programs\n",
    "\n",
    "Chapter 12 of Py4E gets into networked programs, primarily using HyperText Transfer Protocol (http).\n",
    "\n",
    "## Sockets\n",
    "\n",
    "<iframe width=\"640\" height=\"360\" src=\"https://web.microsoftstream.com/embed/video/3ca9121e-16b4-40c5-9c55-a1d401d4adc1?autoplay=false&amp;showinfo=true\" allowfullscreen style=\"border:1px;\"></iframe>\n",
    "\n",
    "If the above embeded Microsoft Stream video doesn't work (or you do not have University of Florida GatorLink account, you can [view the video from this Dropbox Link](https://www.dropbox.com/s/r721kvocy27tm5f/Py4E_Ch_12_Netwoked_Programs_1.mp4?dl=0)).\n",
    "\n",
    "This chapter introduces the concept of a **socket**. This is something that will continue to come up, so is important to understand. \n",
    "\n",
    "In many ways, a socket is like a file handle--it provides access to the information, not the information itself. However, a socket is different in that it provides **two-way** communication for sending *and* recieving information.\n",
    "\n",
    "Here, we'll use sockets to connect to a web server and get the contents of a web page. Different from opening a file on disk, more coordination is needed between your computer and the web server to transmit data, confirm reciept of data, etc. Later, we'll use sockets to connect to databases. And again coordination and established protocols for sending and receiving data come into play.\n",
    "\n",
    "## Protocols\n",
    "\n",
    "<iframe width=\"640\" height=\"360\" src=\"https://web.microsoftstream.com/embed/video/2a164d8e-3eaa-4cfb-b701-6e17351b80f3?autoplay=false&amp;showinfo=true\" allowfullscreen style=\"border:none;\"></iframe>\n",
    "\n",
    "If the above embeded Microsoft Stream video doesn't work (or you do not have University of Florida GatorLink account, you can [view the video from this Dropbox Link](https://www.dropbox.com/s/mijp33jho9l8hx1/Py4E_Ch_12_Netwoked_Programs_2.mp4?dl=0)).\n",
    "\n",
    "As described in the text, in order for two computers to communicate successfully, they need to be following some protocol, or established proceedures for communicating. HTTP is one protocol. We looked briefly at the SFTP (Secure File Transfer Protocol) earlier in the semester for transfering files from our computers to the cluster. Other protocols you may be familiar with include Internet Message Access Protocol (IMAP), Post Office Protocol version 3 (POP3) and Simple Mail Transfer Protocol (SMTP) all used for email systems.\n",
    "\n",
    "There are many protocols for different types of communications, the important thing is that you need to establish which protocol is being used and follow the specifications of that protocol.\n",
    "\n",
    "## 12.2 The worldâ€™s simplest web browser (p. 142)\n",
    "\n",
    "Here's the code for socket1.py (remember these are in the code3 directory of the repository)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "HTTP/1.1 200 OK\n",
      "Date: Tue, 13 Oct 2020 14:44:18 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Last-Modified: Sat, 13 May 2017 11:22:22 GMT\n",
      "ETag: \"a7-54f6609245537\"\n",
      "Accept-Ranges: bytes\n",
      "Content-Length: 167\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\n",
      "Pragma: no-cache\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\n",
      "Connection: close\n",
      "Content-Type: text/plain\n",
      "\n",
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512) \n",
    "    if (len(data) < 1):\n",
    "        break\n",
    "    print(data.decode(),end='')\n",
    "\n",
    "mysock.close()\n",
    "\n",
    "# Code: http://www.py4e.com/code3/socket1.py"
   ]
  },
  {
   "source": [
    "Note that if you navigate to [http://data.pr4e.org/romeo.txt](http://data.pr4e.org/romeo.txt) in your browser, you see the content, but not the headers--your web browser uses the headers to understand the content and format it correctly for you."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.3 Retrieving an image of HTTP (p. 144)\n",
    "\n",
    "<iframe width=\"640\" height=\"360\" src=\"https://web.microsoftstream.com/embed/video/0f353d5c-0dc3-4a75-b543-51a63f56c348?autoplay=false&amp;showinfo=true\" allowfullscreen style=\"border:none;\"></iframe>\n",
    "\n",
    "\n",
    "If the above embeded Microsoft Stream video doesn't work (or you do not have University of Florida GatorLink account, you can [view the video from this Dropbox Link](https://www.dropbox.com/s/yoa23jop4ydhhsu/Py4E_Ch_12_Netwoked_Programs_3.mp4?dl=0)).\n",
    "\n",
    "Take a look at the `urljpeg.py` script, which downloads an image, and the information on the script in the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5120 5120\n",
      "5120 10240\n",
      "4360 14600\n",
      "5120 19720\n",
      "5120 24840\n",
      "5120 29960\n",
      "5120 35080\n",
      "5120 40200\n",
      "680 40880\n",
      "5120 46000\n",
      "720 46720\n",
      "5120 51840\n",
      "5120 56960\n",
      "5120 62080\n",
      "5120 67200\n",
      "5120 72320\n",
      "5120 77440\n",
      "5120 82560\n",
      "5120 87680\n",
      "5120 92800\n",
      "3560 96360\n",
      "5120 101480\n",
      "720 102200\n",
      "5120 107320\n",
      "720 108040\n",
      "5120 113160\n",
      "5120 118280\n",
      "2900 121180\n",
      "5120 126300\n",
      "5120 131420\n",
      "5120 136540\n",
      "3620 140160\n",
      "5120 145280\n",
      "5120 150400\n",
      "5120 155520\n",
      "5120 160640\n",
      "5120 165760\n",
      "5120 170880\n",
      "5120 176000\n",
      "5120 181120\n",
      "5120 186240\n",
      "2100 188340\n",
      "5120 193460\n",
      "5120 198580\n",
      "4360 202940\n",
      "5120 208060\n",
      "5120 213180\n",
      "5120 218300\n",
      "700 219000\n",
      "5120 224120\n",
      "5120 229240\n",
      "1368 230608\n",
      "Header length 394\n",
      "HTTP/1.1 200 OK\n",
      "Date: Tue, 13 Oct 2020 14:50:51 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Last-Modified: Mon, 15 May 2017 12:27:40 GMT\n",
      "ETag: \"38342-54f8f2e5b6277\"\n",
      "Accept-Ranges: bytes\n",
      "Content-Length: 230210\n",
      "Vary: Accept-Encoding\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\n",
      "Pragma: no-cache\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\n",
      "Connection: close\n",
      "Content-Type: image/jpeg\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import time\n",
    "\n",
    "HOST = 'data.pr4e.org'\n",
    "PORT = 80\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect((HOST, PORT))\n",
    "mysock.sendall(b'GET http://data.pr4e.org/cover3.jpg HTTP/1.0\\r\\n\\r\\n')\n",
    "count = 0\n",
    "picture = b\"\"\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(5120)\n",
    "    if len(data) < 1: break\n",
    "    #time.sleep(0.25)\n",
    "    count = count + len(data)\n",
    "    print(len(data), count)\n",
    "    picture = picture + data\n",
    "\n",
    "mysock.close()\n",
    "\n",
    "# Look for the end of the header (2 CRLF)\n",
    "pos = picture.find(b\"\\r\\n\\r\\n\")\n",
    "print('Header length', pos)\n",
    "print(picture[:pos].decode())\n",
    "\n",
    "# Skip past the header and save the picture data\n",
    "picture = picture[pos+4:]\n",
    "fhand = open(\"stuff.jpg\", \"wb\")\n",
    "fhand.write(picture)\n",
    "fhand.close()\n",
    "\n",
    "# Code: http://www.py4e.com/code3/urljpeg.py"
   ]
  },
  {
   "source": [
    "Hopefully most of this makes some sense, but starts looking kind of messy...The next sections will show you that while you *can* work at this low-level and write code to speak directly to the remote server, there are modules to simplify this. But fundementally, they are providing an easier user experience to the same functionality."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "## 12.4 Retrieving web pages with `urllib`\n",
    "\n",
    "<iframe width=\"640\" height=\"360\" src=\"https://web.microsoftstream.com/embed/video/8a6c6540-62bd-4964-84c2-aadb8a3d81de?autoplay=false&amp;showinfo=true\" allowfullscreen style=\"border:none;\"></iframe>\n",
    "\n",
    "If the above embeded Microsoft Stream video doesn't work (or you do not have University of Florida GatorLink account, you can [view the video from this Dropbox Link](https://www.dropbox.com/s/90t1by1d0dtz6fp/Py4E_Ch_12_Netwoked_Programs_4.mp4?dl=0)).\n",
    "\n",
    "The `urllib` module makes getting stuff from the web a bit easier. The `socket1.py` script above can be simplified to:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt') \n",
    "for line in fhand:\n",
    "    print(line.decode().strip())\n",
    "# Code: http://www.py4e.com/code3/urllib1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `urllib` sits between the script and the socket to make an opened socket look just like a file handle and we can treat the web page in much the same way as we treat a local file."
   ]
  },
  {
   "source": [
    "## 12.5 Reading binary files using `urllib`\n",
    "\n",
    "And the rather messy `urljpg.py` to download an image is simplified to:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "img = urllib.request.urlopen('http://data.pr4e.org/cover3.jpg').read()\n",
    "fhand = open('cover3.jpg', 'wb')\n",
    "fhand.write(img)\n",
    "fhand.close()\n",
    "# Code: http://www.py4e.com/code3/curl1.py"
   ]
  },
  {
   "source": [
    "The chapter goes on to show how to write out chunks of the file so as not to accumulate everything in RAM. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.7 Parsing HTML using regular expressions (p. 149)\n",
    "\n",
    "We could write our own scripts to parse HTML looking for information. The example here is using a regular expression to search for a link and make a list of links on a page.\n",
    "\n",
    "Run `urlregex.py` on some site, google.com for example:\n",
    "\n",
    "```bash\n",
    "[magitz@login2 code3]$ python3 urlregex.py\n",
    "Enter - http://google.com\n",
    "http://www.google.com/imghp?hl=en&tab=wi\n",
    "http://maps.google.com/maps?hl=en&tab=wl\n",
    "https://play.google.com/?hl=en&tab=w8\n",
    "http://www.youtube.com/?gl=US&tab=w1\n",
    "http://news.google.com/nwshp?hl=en&tab=wn\n",
    "https://mail.google.com/mail/?tab=wm\n",
    "https://drive.google.com/?tab=wo\n",
    "https://www.google.com/intl/en/options/\n",
    "http://www.google.com/history/optout?hl=en\n",
    "https://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=http://www.google.com/\n",
    "https://plus.google.com/116899029375914044550\n",
    "[magitz@login2 code3]$ \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, not all web pages follow HTML guidelines totally and sometimes pages can be really hard to parse. Tags can be upper and lower case, some closing tags are optional, etc. It can quickly get quite complex.\n",
    "\n",
    "## 12.8 Parsing HTML using BeautifulSoup\n",
    "\n",
    "As I mentioned earlier, whatever you are trying to do, look for a module to make your life easier. If you need to parse HTML, don't start trying to write your own script to do it, look at available modules. One is `BeautifulSoup` available from crummy.com--some people sure have fun naming things!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "https://www.google.com/imghp?hl=en&tab=wi\nhttps://maps.google.com/maps?hl=en&tab=wl\nhttps://play.google.com/?hl=en&tab=w8\nhttps://www.youtube.com/?gl=US&tab=w1\nhttps://news.google.com/nwshp?hl=en&tab=wn\nhttps://mail.google.com/mail/?tab=wm\nhttps://drive.google.com/?tab=wo\nhttps://www.google.com/intl/en/about/products?tab=wh\nhttp://www.google.com/history/optout?hl=en\n/preferences?hl=en\nhttps://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=https://www.google.com/\n/search?ie=UTF-8&q=popular+Google+Doodle+games&oi=ddle&ct=153499290&hl=en&sa=X&ved=0ahUKEwiY6NeisZ_pAhXClXIEHaVpCZMQPQgD\n/advanced_search?hl=en&authuser=0\nhttps://www.google.com/url?q=https://www.youtube.com/stayhome%3Futm_source%3Dgoogle%26utm_medium%3Dhppromo%26utm_campaign%3DHelpathomeYTUS&source=hpp&id=19017550&ct=3&usg=AFQjCNE2FZizHR5ncV3c9xnzo6f1UpGKmQ&sa=X&ved=0ahUKEwiY6NeisZ_pAhXClXIEHaVpCZMQ8IcBCAU\n/intl/en/ads/\n/services/\n/intl/en/about.html\n/intl/en/policies/privacy/\n/intl/en/policies/terms/\n"
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ')\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a') \n",
    "for tag in tags:\n",
    "    print(tag.get('href', None))\n",
    "\n",
    "# Code: http://www.py4e.com/code3/urllinks.py\n"
   ]
  },
  {
   "source": [
    "## Where to go from here?\n",
    "\n",
    "There's lots of data on the web and lots of our world lives online..Explore options and think about data sources you are interested in.\n",
    "\n",
    "The next chapter goes beyond getting information from web pages to interacting with networked applications using API (Application Programming Interfaces)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}